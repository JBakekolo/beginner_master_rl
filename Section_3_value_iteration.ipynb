{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Section_3_value_iteration.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Tdgz8uplkvKF"
      },
      "source": [
        "<div style=\"text-align:center\">\n",
        "    <h1>\n",
        "        Value Iteration\n",
        "    </h1>\n",
        "</div>\n",
        "<br>\n",
        "\n",
        "<div style=\"text-align:center\">\n",
        "    <p>\n",
        "        In this notebook we are going to look at a dynamic programming algorithm called value iteration. In it, we will sweep the state space and update all the V(s) values.\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<br><br>\n",
        "<div style=\"text-align:center\">\n",
        "    <b>This notebook belongs to section 3 of the course \"Reinforcement Learning: beginner to master\".</b>\n",
        "    <br><br>\n",
        "    <a href=\"https://www.udemy.com\">Reinforcement Learning: beginner to master</a> (English)\n",
        "    <br>\n",
        "    <a href=\"https://www.udemy.com\">Reinforcement Learning: de principiante a maestro</a> (Spanish)\n",
        "</div>\n",
        "\n",
        "<br>\n",
        "\n",
        "<table style=\"width:35%\">\n",
        "  <tr style=\"background-color: transparent\">\n",
        "    <td style=\"width: 45%\">\n",
        "        <a target=\"_parent\" href=\"https://www.evlabs.io\" style=\"float: center\">\n",
        "            <img src=\"https://github.com/JBakekolo/beginner_master_rl/blob/main/img/evlabs-square.png?raw=1\" width=\"75\"/>\n",
        "        </a> \n",
        "    </td>\n",
        "    <td valign=\"bottom\">\n",
        "        <a target=\"_parent\" href=\"https://www.youtube.com/channel/UCksRNSzWuMV5IfdrPlglqqw\">\n",
        "            <img src=\"https://github.com/JBakekolo/beginner_master_rl/blob/main/img/YouTube.png?raw=1\" width=\"35\"/>\n",
        "        </a> \n",
        "    </td>\n",
        "    <td>\n",
        "        <a target=\"_parent\" href=\"https://www.linkedin.com/company/evlabs\">\n",
        "            <img src=\"https://github.com/JBakekolo/beginner_master_rl/blob/main/img/LinkedIn.png?raw=1\" width=\"35\"/>\n",
        "        </a> \n",
        "    </td>\n",
        "    <td>\n",
        "        <a target=\"_parent\" href=\"https://twitter.com/evelabs\">\n",
        "            <img src=\"https://github.com/JBakekolo/beginner_master_rl/blob/main/img/Twitter.png?raw=1\" width=\"35\"/>\n",
        "        </a> \n",
        "    </td>\n",
        "    <td>\n",
        "        <a target=\"_parent\" href=\"https://github.com/escape-velocity-labs/\">\n",
        "            <img src=\"https://github.com/JBakekolo/beginner_master_rl/blob/main/img/GitHub.png?raw=1\" width=\"35\"/>\n",
        "        </a> \n",
        "    </td>\n",
        "\n",
        "  </tr>\n",
        "  <tr style=\"background-color: transparent\">\n",
        "    <th style=\"text-align: center; width: 70%\">Escape Velocity Labs</th>\n",
        "  </tr>\n",
        "\n",
        "</table>\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrJzika2kvKs"
      },
      "source": [
        "## Import the necessary software libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa5gWcqbkvKw",
        "outputId": "f175cbfe-f7fb-4402-8544-85c53f1ee781",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "1+5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruiNVcT8kvK2"
      },
      "source": [
        "## Initialize the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nq5nNiakvK5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgn9vCgZkvLN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3NU4fdpkvLR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls83-0hQkvLX"
      },
      "source": [
        "## Define the policy $\\pi(\\cdot|s)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK5afTF-kvLd"
      },
      "source": [
        "#### Create the policy $\\pi(\\cdot|s)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcYjsZCFkvLh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL3rWYaCkvLk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BscrRfCLkvLm"
      },
      "source": [
        "#### Test the policy with state (0, 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C-_bvSHkvLp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0jlhud2kvLr"
      },
      "source": [
        "#### See how the random policy does in the maze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51_ZgD8vkvLt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weDDuE9EkvLw"
      },
      "source": [
        "#### Plot the policy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnkfeG7ukvLz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRV4PtvGkvL1"
      },
      "source": [
        "## Define value table $V(s)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF0s2T0ZkvL4"
      },
      "source": [
        "#### Create the $V(s)$ table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvllQoj1kvL7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyFbKOqgkvL-"
      },
      "source": [
        "#### Plot $V(s)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0mINPi7kvL_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLAMRpplkvMA"
      },
      "source": [
        "## Implement the Value Iteration algorithm\n",
        "\n",
        "</br>\n",
        "\n",
        "\n",
        "![Screenshot%202021-02-10%20at%2015.36.48.png](attachment:Screenshot%202021-02-10%20at%2015.36.48.png)\n",
        "\n",
        "<div style=\"text-align:center\">\n",
        "    Adapted from Barto & Sutton: \"Reinforcement Learning: An Introduction\".\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-QW0qEfkvMC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WNgh9KpkvMD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dLkZfF5kvME"
      },
      "source": [
        "## Show results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLa9nNAJkvMF"
      },
      "source": [
        "#### Show resulting value table $V(s)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s6QXr99kvMG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U32rCz3ikvMH"
      },
      "source": [
        "#### Show resulting policy $\\pi(\\cdot|s)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSLp-lDdkvMJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuqNhaf2kvMJ"
      },
      "source": [
        "#### Test the resulting agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNV_U1YVkvMM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRL4X8-dkvMN"
      },
      "source": [
        "## Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KREvoJg-kvMP"
      },
      "source": [
        "[[1] Reinforcement Learning: An Introduction. Ch. 4: Dynamic Programming](https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf)"
      ]
    }
  ]
}